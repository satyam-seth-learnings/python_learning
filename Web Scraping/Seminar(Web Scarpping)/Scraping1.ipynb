{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get('https://blog.scrapinghub.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a soup for analysis\n",
    "soup=BeautifulSoup(page.text,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "heading=soup.find_all('h2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h2 class=\"site-description\">Turn Web Content Into Useful Data</h2>,\n",
       " <h2><a href=\"https://blog.scrapinghub.com/scrapy-autoextract-api-integration\">Scrapy &amp; AutoExtract API integration</a></h2>,\n",
       " <h2><a href=\"https://blog.scrapinghub.com/web-scraping-questions-answers-part-1\">Web Scraping Questions &amp; Answers Part I</a></h2>,\n",
       " <h2><a href=\"https://blog.scrapinghub.com/price-intelligence-with-python-scrapy-sql-pandas\">Price intelligence with Python: Scrapy, SQL and Pandas</a></h2>,\n",
       " <h2><a href=\"https://blog.scrapinghub.com/the-web-data-extraction-summit-2019\">The Web Data Extraction Summit 2019</a></h2>,\n",
       " <h2><a href=\"https://blog.scrapinghub.com/news-data-extraction-at-scale-with-ai-powered-autoextract\">News Data Extraction at Scale with AI powered AutoExtract</a></h2>,\n",
       " <h2><a href=\"https://blog.scrapinghub.com/gain-a-competitive-edge-with-product-data\">Gain a Competitive Edge with Product Data</a></h2>,\n",
       " <h2><a href=\"https://blog.scrapinghub.com/use-cases-for-online-public-sentiment-data\">Four Use Cases for Online Public Sentiment Data</a></h2>,\n",
       " <h2><a href=\"https://blog.scrapinghub.com/the-first-web-data-extraction-summit\">The First-Ever Web Data Extraction Summit!</a></h2>,\n",
       " <h2><a href=\"https://blog.scrapinghub.com/python-requests-proxy\">How to use proxies with Python Requests module</a></h2>,\n",
       " <h2><a href=\"https://blog.scrapinghub.com/scrapy-proxy\">How to set up a custom proxy in Scrapy?</a></h2>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Turn Web Content Into Useful Data\n",
      ">> Scrapy & AutoExtract API integration\n",
      ">> Web Scraping Questions & Answers Part I\n",
      ">> Price intelligence with Python: Scrapy, SQL and Pandas\n",
      ">> The Web Data Extraction Summit 2019\n",
      ">> News Data Extraction at Scale with AI powered AutoExtract\n",
      ">> Gain a Competitive Edge with Product Data\n",
      ">> Four Use Cases for Online Public Sentiment Data\n",
      ">> The First-Ever Web Data Extraction Summit!\n",
      ">> How to use proxies with Python Requests module\n",
      ">> How to set up a custom proxy in Scrapy?\n"
     ]
    }
   ],
   "source": [
    "for item in heading:\n",
    "    print('>>',item.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates=soup.find_all('span',attrs={'class':'date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date= October 15, 2019\n",
      "date= October 10, 2019\n",
      "date= October 08, 2019\n",
      "date= September 26, 2019\n",
      "date= September 17, 2019\n",
      "date= September 12, 2019\n",
      "date= September 05, 2019\n",
      "date= August 29, 2019\n",
      "date= August 22, 2019\n",
      "date= August 08, 2019\n"
     ]
    }
   ],
   "source": [
    "for item in dates:\n",
    "    print('date=',item.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors=soup.find_all('span',attrs={'class':'author'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author= Attila Tóth\n",
      "author= Attila Tóth\n",
      "author= Attila Tóth\n",
      "author= Attila Tóth\n",
      "author= Attila Tóth\n",
      "author= Marie Moynihan\n",
      "author= Marie Moynihan\n",
      "author= Marie Moynihan\n",
      "author= Attila Tóth\n",
      "author= Attila Tóth\n"
     ]
    }
   ],
   "source": [
    "for item in authors:\n",
    "    print('author=',item.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments=soup.find_all('span',attrs={'class':'custom_listing_comments'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comment= 0 Comment\n",
      "comment= 0 Comment\n",
      "comment= 0 Comment\n",
      "comment= 0 Comment\n",
      "comment= 1 Comment\n",
      "comment= 0 Comment\n",
      "comment= 0 Comment\n",
      "comment= 0 Comment\n",
      "comment= 0 Comment\n",
      "comment= 1 Comment\n"
     ]
    }
   ],
   "source": [
    "for item in comments:\n",
    "    print('comment=',item.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving data as dataset\n",
    "dataset=[] #empty list\n",
    "for h,d,a,c in zip(heading,dates,authors,comments):\n",
    "    dataset.append({\n",
    "        'heading':h.text,\n",
    "        'date':d.text.strip(),\n",
    "        'author':a.text.strip(),\n",
    "        'comments':c.text.strip(),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "import pandas as pd\n",
    "df=pd.DataFrame(dataset)\n",
    "df.to_csv('scraping.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>comments</th>\n",
       "      <th>date</th>\n",
       "      <th>heading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Attila Tóth</td>\n",
       "      <td>0 Comment</td>\n",
       "      <td>October 15, 2019</td>\n",
       "      <td>Turn Web Content Into Useful Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Attila Tóth</td>\n",
       "      <td>0 Comment</td>\n",
       "      <td>October 10, 2019</td>\n",
       "      <td>Scrapy &amp; AutoExtract API integration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attila Tóth</td>\n",
       "      <td>0 Comment</td>\n",
       "      <td>October 08, 2019</td>\n",
       "      <td>Web Scraping Questions &amp; Answers Part I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Attila Tóth</td>\n",
       "      <td>0 Comment</td>\n",
       "      <td>September 26, 2019</td>\n",
       "      <td>Price intelligence with Python: Scrapy, SQL an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Attila Tóth</td>\n",
       "      <td>1 Comment</td>\n",
       "      <td>September 17, 2019</td>\n",
       "      <td>The Web Data Extraction Summit 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Marie Moynihan</td>\n",
       "      <td>0 Comment</td>\n",
       "      <td>September 12, 2019</td>\n",
       "      <td>News Data Extraction at Scale with AI powered ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Marie Moynihan</td>\n",
       "      <td>0 Comment</td>\n",
       "      <td>September 05, 2019</td>\n",
       "      <td>Gain a Competitive Edge with Product Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Marie Moynihan</td>\n",
       "      <td>0 Comment</td>\n",
       "      <td>August 29, 2019</td>\n",
       "      <td>Four Use Cases for Online Public Sentiment Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Attila Tóth</td>\n",
       "      <td>0 Comment</td>\n",
       "      <td>August 22, 2019</td>\n",
       "      <td>The First-Ever Web Data Extraction Summit!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Attila Tóth</td>\n",
       "      <td>1 Comment</td>\n",
       "      <td>August 08, 2019</td>\n",
       "      <td>How to use proxies with Python Requests module</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           author   comments                date  \\\n",
       "0     Attila Tóth  0 Comment    October 15, 2019   \n",
       "1     Attila Tóth  0 Comment    October 10, 2019   \n",
       "2     Attila Tóth  0 Comment    October 08, 2019   \n",
       "3     Attila Tóth  0 Comment  September 26, 2019   \n",
       "4     Attila Tóth  1 Comment  September 17, 2019   \n",
       "5  Marie Moynihan  0 Comment  September 12, 2019   \n",
       "6  Marie Moynihan  0 Comment  September 05, 2019   \n",
       "7  Marie Moynihan  0 Comment     August 29, 2019   \n",
       "8     Attila Tóth  0 Comment     August 22, 2019   \n",
       "9     Attila Tóth  1 Comment     August 08, 2019   \n",
       "\n",
       "                                             heading  \n",
       "0                  Turn Web Content Into Useful Data  \n",
       "1               Scrapy & AutoExtract API integration  \n",
       "2            Web Scraping Questions & Answers Part I  \n",
       "3  Price intelligence with Python: Scrapy, SQL an...  \n",
       "4                The Web Data Extraction Summit 2019  \n",
       "5  News Data Extraction at Scale with AI powered ...  \n",
       "6          Gain a Competitive Edge with Product Data  \n",
       "7    Four Use Cases for Online Public Sentiment Data  \n",
       "8         The First-Ever Web Data Extraction Summit!  \n",
       "9     How to use proxies with Python Requests module  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
